 # dataset from https://www.lendingclub.com/info/download-data.action
 dataset_r = read.csv('RejectStats_2017Q4.csv',header=T,sep=',')
> dataset_a = read.csv('LoanStats_2017Q4.csv',header=T,sep=',')
> View(head(dataset_r))
> View(head(dataset_a))
> 
> ####CLEANING### added additional column for approved and rejected loans requests, renamed columns to match in both tables
>    dataset_r =dataset_r[,c(-2,-4,-6,-7)]
>    dataset_r = mutate(dataset_r, apprej = "rej")
>    dataset_a =dataset_a[,c(4,12,22,25,52)]
>    dataset_a = mutate(dataset_a, apprej = "app")
>    names(dataset_a) = c("amount","emp","title","dti","policy","apprej")
>    names(dataset_r) = c("amount","title","dti","emp","policy","apprej")
> 
>   #Union data from rejected file with the funded loan file
>    for(i in c(1:ncol(dataset_a))){
+      dataset_r[,i] = as.factor(dataset_r[,i])
+    }
>    for(i in c(1:ncol(dataset_a))){
+      dataset_a[,i] = as.factor(dataset_a[,i])
+    }  
>    
>    dataset= union_all(dataset_a,dataset_r)
There were 18 warnings (use warnings() to see them)
>    warnings()
Warning messages:
1: In bind_rows_(x, .id) : Unequal factor levels: coercing to character
2: In bind_rows_(x, .id) :
  binding character and factor vector, coercing into character vector
3: In bind_rows_(x, .id) :
  binding character and factor vector, coercing into character vector
4: In bind_rows_(x, .id) : Unequal factor levels: coercing to character
5: In bind_rows_(x, .id) :
  binding character and factor vector, coercing into character vector
6: In bind_rows_(x, .id) :
  binding character and factor vector, coercing into character vector
7: In bind_rows_(x, .id) : Unequal factor levels: coercing to character
8: In bind_rows_(x, .id) :
  binding character and factor vector, coercing into character vector
9: In bind_rows_(x, .id) :
  binding character and factor vector, coercing into character vector
10: In bind_rows_(x, .id) : Unequal factor levels: coercing to character
11: In bind_rows_(x, .id) :
  binding character and factor vector, coercing into character vector
12: In bind_rows_(x, .id) :
  binding character and factor vector, coercing into character vector
13: In bind_rows_(x, .id) : Unequal factor levels: coercing to character
14: In bind_rows_(x, .id) :
  binding character and factor vector, coercing into character vector
15: In bind_rows_(x, .id) :
  binding character and factor vector, coercing into character vector
16: In bind_rows_(x, .id) : Unequal factor levels: coercing to character
17: In bind_rows_(x, .id) :
  binding character and factor vector, coercing into character vector
18: In bind_rows_(x, .id) :
  binding character and factor vector, coercing into character vector
>    View(head(dataset))
>    
>    
>    ##Find NA= , omit if few
>     for(i in c(1:ncol(dataset)))  {
+       if(sum(is.na(dataset[i])) > 0)
+        print(c(sum(is.na(dataset[i])),colnames(dataset[i])))
+     }
[1] "2"      "amount"
[1] "224" "dti"
[1] "2"      "policy"
>     ##omit or replace NAs
>         na.omit(dataset$dti)
   [1] "7.88"   "32.01"  "25.41"  "0.56"   "6.74"   "26.81"  "27.98"  "37.12"  "24.23"  "17.48"  "25.75"  "16.4"   "23.69" 
  [14] "18.84"  "8.52"   "2.17"   "5.82"   "22.08"  "28.54"  "27.28"  "5.83"   "25.95"  "13.42"  "26.95"  "27.74"  "11.35" 
  [27] "24.45"  "11.21"  "21.7"   "16.07"  "9.62"   "18.18"  "20.74"  "34.96"  "25.46"  "8.35"   "8.84"   "5.75"   "10.22" 
  [40] "15.02"  "21.46"  "24.75"  "12.85"  "24.23"  "2.64"   "27.96"  "30.86"  "4.58"   "49.13"  "14.22"  "21.38"  "21.03" 
  [53] "17.3"   "26.53"  "17.58"  "13.18"  "33.28"  "5.99"   "11.17"  "28.11"  "39.4"   "7.76"   "0.83"   "30.33"  "21.49" 
  [66] "23.48"  "36.8"   "13.02"  "11.92"  "13.29"  "23.43"  "19.72"  "16.86"  "14.84"  "67.28"  "23.78"  "3.72"   "24.26" 
  [79] "20.77"  "17.22"  "11.94"  "6.43"   "29.73"  "4.67"   "12.26"  "11.86"  "8.7"    "26.21"  "20.97"  "30.04"  "7.99"  
  [92] "7.71"   "21.88"  "28.83"  "25.62"  "15.5"   "6.52"   "20.33"  "8.89"   "34.26"  "18.32"  "31.17"  "13.53"  "13.4"  
 [105] "13.52"  "15.72"  "13.61"  "27.53"  "16.53"  "11.63"  "10.6"   "11.62"  "21.92"  "0"      "18.49"  "11.77"  "18.19" 
 [118] "23.05"  "9.81"   "4.86"   "28.63"  "12.22"  "34.01"  "18.74"  "1.03"   "4.1"    "24.36"  "21.63"  "30.86"  "26.79" 
 [131] "27.03"  "7.28"   "4.85"   "33.48"  "23.01"  "5.76"   "18.12"  "21.47"  "6.89"   "14.19"  "17.75"  "33.26"  "27.28" 
 [144] "16.07"  "5.67"   "18.12"  "19.75"  "21.16"  "20.42"  "23.11"  "3.88"   "5.96"   "19.04"  "4.36"   "21.38"  "9.24"  
 [157] "16.46"  "2.93"   "9.22"   "21.73"  "19.68"  "2.14"   "22.02"  "35.17"  "14.72"  "40.07"  "12.6"   "12.27"  "13.33" 
 [170] "11.46"  "30.86"  "8.23"   "11.23"  "11.53"  "19.37"  "13.15"  "22.04"  "18.34"  "11.98"  "10.29"  "31.68"  "1.62"  
 [183] "25.89"  "21.82"  "7.26"   "20.24"  "31.64"  "1.81"   "9.2"    "8.72"   "30.29"  "144.66" "26.25"  "19.14"  "20.3"  
 [196] "26.38"  "37.17"  "6.93"   "44.68"  "10.04"  "8.55"   "6.62"   "9.23"   "27.26"  "20.87"  "6.94"   "3.9"    "14.08" 
 [209] "20.06"  "9.48"   "38.1"   "6.13"   "12.62"  "26.18"  "1.25"   "19.24"  "20.42"  "24.5"   "10.07"  "15.77"  "27.88" 
 [222] "18.64"  "24.23"  "1"      "18.36"  "16.02"  "13.6"   "22.63"  "8.88"   "29.26"  "24.95"  "8.6"    "24.76"  "33.34" 
 [235] "16.9"   "26.63"  "30.17"  "21.83"  "26.35"  "25.86"  "15.55"  "13.98"  "0.75"   "22.09"  "21.69"  "22.8"   "27.72" 
 [248] "10.59"  "13.36"  "1.73"   "12.1"   "8.04"   "33.58"  "15.45"  "20.2"   "11.93"  "12.17"  "27.06"  "38.96"  "11.73" 
 [261] "10.24"  "3.73"   "26.3"   "30.16"  "33.24"  "21.17"  "16"     "9.54"   "24.97"  "32.48"  "23.65"  "22.22"  "34.77" 
 [274] "2.93"   "5.95"   "7.1"    "18.63"  "12.05"  "15.43"  "27.79"  "9.16"   "24.75"  "7.29"   "7.31"   "22.2"   "24.41" 
 [287] "5.53"   "8.64"   "9.35"   "36.41"  "51.41"  "35.18"  "28.09"  "12.53"  "16.3"   "14.7"   "16.51"  "17.3"   "27.65" 
 [300] "7.9"    "17.73"  "14.33"  "31.14"  "16.32"  "5.99"   "6.92"   "6.55"   "37.43"  "24.47"  "16.67"  "8.14"   "22.43" 
 [313] "19.97"  "21.2"   "28.36"  "12.47"  "21.04"  "10.33"  "22.5"   "8.98"   "30.93"  "13.47"  "6.94"   "29.72"  "82.19" 
 [326] "23.56"  "19.62"  "31.62"  "22.55"  "8.84"   "30.02"  "10.43"  "9.46"   "34.93"  "28.45"  "22.03"  "29.44"  "4.81"  
 [339] "23.04"  "18.19"  "5.14"   "6.31"   "7.89"   "21.41"  "9.59"   "16.17"  "22.05"  "13.24"  "13.37"  "34.4"   "19.14" 
 [352] "3.84"   "33.73"  "4.6"    "19.6"   "61.52"  "20.87"  "30.88"  "19.18"  "16.06"  "17.5"   "8.7"    "19.96"  "10.6"  
 [365] "22.08"  "20.49"  "12.63"  "27.57"  "14.33"  "1.09"   "16.17"  "11.9"   "13.34"  "9.47"   "7.13"   "502.41" "2.16"  
 [378] "22.39"  "36.45"  "28.69"  "29.41"  "16.45"  "13.08"  "19.54"  "9.04"   "8.06"   "22.83"  "34.74"  "19.44"  "5.49"  
 [391] "25.06"  "23.04"  "13.23"  "30.4"   "10.2"   "25"     "7.07"   "24.25"  "20.15"  "19.4"   "9.09"   "4.31"   "14.93" 
 [404] "21.76"  "4.27"   "21.63"  "33.33"  "10.49"  "14.74"  "14.56"  "5.73"   "14.63"  "33.59"  "26.53"  "3.27"   "10.83" 
 [417] "21.96"  "26.55"  "24.51"  "25.75"  "12.55"  "31.07"  "18.98"  "12.67"  "6.13"   "5.23"   "0.64"   "17.31"  "23.94" 
 [430] "4.67"   "8.51"   "14.18"  "7.45"   "29.74"  "1.03"   "41.96"  "16.96"  "13.24"  "14.94"  "10.77"  "16.33"  "31.05" 
 [443] "6.25"   "11.34"  "24.18"  "27.71"  "9.22"   "20.84"  "9.01"   "12.71"  "14.68"  "20.19"  "59.71"  "10.44"  "18.51" 
 [456] "25.65"  "8.86"   "20.03"  "6.99"   "23.61"  "9.85"   "13.04"  "28.46"  "11.24"  "12.87"  "33.02"  "17"     "28.58" 
 [469] "10.03"  "28.24"  "20.06"  "23.12"  "14.38"  "12.52"  "26.72"  "24.95"  "14.18"  "22.21"  "27.46"  "5.35"   "27.67" 
 [482] "20.14"  "1.9"    "32.78"  "5.92"   "14.07"  "21.63"  "18.61"  "27.02"  "25.16"  "19.28"  "7.05"   "24.69"  "37.16" 
 [495] "20.25"  "36.33"  "31.59"  "27.42"  "16.78"  "16.88"  "12.71"  "16.2"   "28.99"  "63.16"  "21.3"   "19"     "20.92" 
 [508] "8.27"   "10.22"  "10.2"   "6.32"   "10.4"   "5.01"   "22.46"  "13.28"  "13.94"  "24.36"  "20.89"  "14.73"  "48.62" 
 [521] "19.75"  "25.43"  "1.74"   "15.47"  "16.99"  "34.62"  "34.8"   "30.27"  "10.69"  "34.95"  "27.87"  "22.58"  "2"     
 [534] "26.51"  "30.15"  "10.95"  "11.11"  "18.34"  "48.4"   "16.73"  "7.07"   "26.59"  "29.83"  "45.93"  "21.65"  "27.24" 
 [547] "15.64"  "19.07"  "18.29"  "22.87"  "20.87"  "19.99"  "34.29"  "18.18"  "31.19"  "27.55"  "26.75"  "27.07"  "21.36" 
 [560] "26.52"  "19.68"  "52.92"  "12.56"  "28.88"  "13.69"  "19.01"  "13.94"  "30"     "7.74"   "3.63"   "20.61"  "14.94" 
 [573] "25.57"  "2.43"   "13.35"  "22.77"  "27.17"  "6.1"    "8.66"   "8.19"   "36.96"  "12.44"  "12.53"  "1.3"    "38.51" 
 [586] "23.07"  "10.8"   "26.91"  "36.83"  "17.86"  "22.58"  "7.49"   "4.68"   "21.01"  "35.51"  "4.86"   "0.6"    "33.59" 
 [599] "30.44"  "27.72"  "31.58"  "18.46"  "18.17"  "12.42"  "48.34"  "21.74"  "19.41"  "10.47"  "22.5"   "17.91"  "5.11"  
 [612] "18.97"  "2.85"   "1.02"   "19.25"  "27.67"  "14.37"  "29.87"  "14.23"  "14.78"  "17.67"  "14.69"  "23.67"  "23.34" 
 [625] "7.26"   "16.91"  "14.44"  "43.99"  "35.13"  "33.58"  "30.9"   "12.25"  "61.72"  "16.49"  "8.68"   "18.89"  "7.21"  
 [638] "37.12"  "16.12"  "13.23"  "14.78"  "28.26"  "23.71"  "21.37"  "1.08"   "7.75"   "13.87"  "12.17"  "36.12"  "17.3"  
 [651] "21.15"  "14.51"  "76.63"  "31.68"  "13.24"  "27.13"  "7.96"   "18.96"  "8.53"   "0"      "45.48"  "28.24"  "26.93" 
 [664] "11.98"  "1.48"   "12.01"  "7.09"   "26.7"   "36.77"  "16.72"  "13.54"  "10.8"   "13.96"  "13.24"  "24.27"  "49.58" 
 [677] "7.3"    "0.34"   "10.35"  "21.21"  "22.23"  "22.22"  "20.42"  "29.24"  "29.77"  "26.65"  "22.08"  "27.46"  "12.34" 
 [690] "15.23"  "20.46"  "21.51"  "3.26"   "13.19"  "7.82"   "29.71"  "7.59"   "3.46"   "10.23"  "22.98"  "17.15"  "7.59"  
 [703] "0"      "29.36"  "20.68"  "24.52"  "22.79"  "6"      "29.18"  "40.21"  "7.63"   "20.05"  "16.67"  "11.06"  "31.28" 
 [716] "23.12"  "15.54"  "20.03"  "9.51"   "1.35"   "35.17"  "23.01"  "26.98"  "28.03"  "34.8"   "25.94"  "30.11"  "30.42" 
 [729] "18.42"  "15.55"  "9.46"   "10.34"  "15.36"  "25.07"  "0.49"   "31.44"  "11.15"  "19.11"  "8.34"   "18.3"   "12.98" 
 [742] "4.81"   "18.72"  "20.32"  "21.49"  "8.9"    "11.89"  "3.29"   "9.58"   "18.1"   "29.92"  "30.13"  "23.44"  "33.94" 
 [755] "8.45"   "20.7"   "9.63"   "14.36"  "15.7"   "10.29"  "12.18"  "12.48"  "19.07"  "12.09"  "12.63"  "21.4"   "16.66" 
 [768] "40.06"  "29.12"  "8.96"   "24.07"  "32.33"  "18.22"  "2.69"   "10.53"  "9.44"   "58.23"  "17.31"  "8.3"    "25.51" 
 [781] "19.08"  "10.1"   "12.3"   "10.99"  "16.22"  "15.2"   "10.32"  "9.08"   "9.47"   "5.58"   "39.44"  "24.59"  "3.83"  
 [794] "15.4"   "8.97"   "6.42"   "16.67"  "10.63"  "22.48"  "21.39"  "11.39"  "25.17"  "33.86"  "18.76"  "38.87"  "27.01" 
 [807] "16.33"  "5.13"   "10.97"  "36.1"   "4.55"   "11.19"  "18.69"  "20.09"  "15.88"  "29.88"  "2.07"   "34.12"  "24.61" 
 [820] "21.9"   "8.92"   "22.64"  "28.46"  "38.44"  "32.58"  "22.23"  "21.82"  "9.25"   "37.48"  "3.5"    "12.15"  "76.31" 
 [833] "2.68"   "17.24"  "11.41"  "7.34"   "15.03"  "9.59"   "18.43"  "38.8"   "34.95"  "34.52"  "37.34"  "17.46"  "17.78" 
 [846] "3.18"   "19.22"  "41.57"  "28.88"  "26.15"  "14.3"   "23.85"  "20.74"  "22.83"  "11.36"  "20.09"  "17.47"  "3.07"  
 [859] "9.12"   "20.61"  "50.38"  "18.9"   "34.86"  "16.27"  "16.64"  "9.47"   "12.34"  "4.14"   "1.67"   "10.74"  "3.03"  
 [872] "5.85"   "30.28"  "3.87"   "12.97"  "14.31"  "39.64"  "12.97"  "20.61"  "4.55"   "23.84"  "16.46"  "27.79"  "3.52"  
 [885] "21.9"   "13.6"   "24.4"   "16.89"  "2.69"   "17.64"  "14.96"  "22.04"  "31.52"  "10.37"  "4.74"   "21.03"  "17.6"  
 [898] "16.15"  "19.16"  "28.84"  "9.94"   "6.15"   "15.9"   "16.47"  "28.3"   "21.95"  "17.49"  "20.82"  "1.24"   "21.88" 
 [911] "12.2"   "9.95"   "12.15"  "10.46"  "18.04"  "13.04"  "13.74"  "40.14"  "4.26"   "17.04"  "26.68"  "18.97"  "5.51"  
 [924] "25.73"  "28.44"  "8.88"   "22.46"  "27.68"  "13.78"  "16.79"  "20.49"  "25.11"  "1.07"   "18.1"   "37.29"  "20.99" 
 [937] "14.43"  "25.06"  "0.32"   "21.06"  "15.89"  "5.44"   "44.7"   "14.72"  "21.59"  "22.53"  "24.39"  "47.6"   "4.42"  
 [950] "18.46"  "23.01"  "35.08"  "18.78"  "11.54"  "19.85"  "3.14"   "15.97"  "17.41"  "17.78"  "27.23"  "16.13"  "9.8"   
 [963] "9.48"   "28.67"  "12.85"  "15.89"  "17.46"  "13.84"  "4.06"   "24.9"   "5.54"   "17.02"  "16.83"  "5.55"   "8.81"  
 [976] "3.31"   "23.02"  "6.79"   "9.94"   "8.86"   "10.28"  "16.8"   "13.89"  "20.55"  "15.47"  "36.71"  "10.18"  "24.42" 
 [989] "740.96" "19.59"  "11.11"  "30.39"  "27.14"  "15.35"  "8.81"   "14.37"  "21.38"  "23.35"  "23.25"  "7.55"  
 [ reached getOption("max.print") -- omitted 2137913 entries ]
attr(,"na.action")
  [1]   1044   1473   1582   2757   3088   4170   4220   4797   5033   5490   5691   6517   6795   7636   8869   9961  10182
 [18]  10721  11084  12316  12708  14751  14871  15287  15428  16020  16160  16377  16780  16982  17303  17358  17791  18764
 [35]  19510  19837  19934  19940  20763  20788  21697  21966  22709  23267  24507  24560  24621  24652  24802  25842  25961
 [52]  26675  27353  28515  28903  28945  29025  29094  31376  31728  32216  32782  33004  33020  34519  35170  35231  35957
 [69]  36556  36983  37640  37913  38400  39152  39292  39626  40692  41056  42093  42096  42357  43002  43675  44903  45216
 [86]  46180  46252  46423  47098  47477  48044  48417  48889  49867  50696  50946  51103  51297  52035  52735  52880  53689
[103]  53933  54998  55066  55177  55261  55371  55977  56878  57072  58188  58294  59180  59560  59885  60153  60310  61371
[120]  62010  63609  63934  64261  64382  64520  65613  65703  66108  66532  67316  67463  67555  67607  68393  68471  68475
[137]  69452  70600  70843  71638  71835  72239  73461  73603  74525  75144  75950  76785  77734  78598  79081  79132  79144
[154]  80226  80310  80463  80574  81471  81476  81624  81629  82941  83576  83732  84119  84303  84785  85038  85874  86124
[171]  86619  87015  88584  88707  89341  90035  90608  90887  91113  91367  91390  91511  92895  93231  93962  94638  95228
[188]  96316  98992  99237  99541  99544  99987 101794 102206 102725 103175 103216 103432 104374 104559 104720 104832 105736
[205] 106159 106796 106815 107894 108002 108317 110280 110406 110953 111777 112003 112110 115537 117610 118136 118146 118519
[222] 118595 118649 118650
attr(,"class")
[1] "omit"
>         na.omit(dataset$policy)
   [1] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
  [31] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
  [61] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
  [91] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [121] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [151] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [181] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [211] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [241] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [271] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [301] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [331] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [361] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [391] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [421] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [451] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [481] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [511] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [541] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [571] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [601] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [631] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [661] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [691] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [721] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [751] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [781] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [811] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [841] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [871] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [901] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [931] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [961] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [991] "1" "1" "1" "1" "1" "1" "1" "1" "1" "1"
 [ reached getOption("max.print") -- omitted 2138135 entries ]
attr(,"na.action")
[1] 118649 118650
attr(,"class")
[1] "omit"
>         
> 
>     ##find ""         
>     for(i in c(1:ncol(dataset_r)))  {
+       print(c(which(dataset_r[i] == ""),colnames(dataset_r[i])))
+       }
[1] "amount"
[1] "title"
[1] "dti"
[1] "emp"
[1] "policy"
[1] "apprej"
>    
> 
> ###SPLIT columns/Substitue values###
>         for(i in c("s","<"," year","+")){
+          dataset$emp = gsub(i,"",dataset$emp, fixed = TRUE)
+           }
>         dataset$emp = gsub("n/a",0,dataset$emp, fixed = TRUE)
>         #dataset$apprej = gsub("rej",1,dataset$apprej, fixed = TRUE)
>         #dataset$apprej = gsub("app",1,dataset$apprej, fixed = TRUE)
> 
> 
> ####New Dataset for Analysis####
>     dataset_r_a = dataset
>     View(head(dataset_r_a))
> 
> ####encoding categorical data#### 
>     for(i in c(3)){
+       dataset_r_a[,i] = as.numeric(as.factor(dataset_r_a[,i]),levels = c(levels(as.factor(dataset_r_a[,i]))), labels= c(1:length(levels(as.factor(dataset_r_a[,i])))))
+     }
>     
> # ###FORMAT### 
>   for(i in c(1:5)) {
+     dataset_r_a[,i] <- as.numeric(as.factor(dataset_r_a[,i]))
+    }
>     dataset_r_a$apprej = as.factor(dataset_r_a$apprej)
>     
> ###**** SPlit Data into training set and test set ****
>     set.seed(1234)
>     split = sample.split(dataset_r_a$apprej, SplitRatio = 0.8)
>     training_set =subset(dataset_r_a, split == TRUE)
>     test_set =subset(dataset_r_a, split == FALSE)
>     
>     
> ###****Feature scaling**** ONLY numeric, NO factors
>     training_set[,c(1:5)] =scale(training_set[,c(1:5)])
>     test_set[,c(1:5)] = scale(test_set[,c(1:5)])
> 
> levels(dataset_r_a$apprej)
[1] "app" "rej"
>     
> ####fitting Logistical regression to training set
>     classifier = glm(formula = apprej~., family = "binomial", data = training_set)
>     prob_pred = predict(classifier, type = 'response' , newdata = test_set[-6]) 
>     y_predict = ifelse(prob_pred>0.5,1,0)
>     View(head(y_predict))
> ####Making the confusion Matrix
>     cm = table(test_set[,6], y_predict)    
>     cm    
     y_predict
           0      1
  app  23676      0
  rej    672 403425
